{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040dd7f6-bcdf-4ba6-aac8-be94681e2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re #re= regular expressins to clean text like number ,lowercase ,specail symbols\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3a0d5-fee6-46e3-b04c-4af9b9bc394e",
   "metadata": {},
   "source": [
    "What is tokenizer?\n",
    "it converts text to numbers\n",
    "why need> neural networks cannot read text\n",
    "\"I love AI\" âŒ\n",
    "[12, 45, 7] âœ…\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71078a1-5b5f-492d-9788-64ffc3eccbf8",
   "metadata": {},
   "source": [
    "Why padding is need?\n",
    "example sentences\n",
    "\"I love AI\"\n",
    "\"Deep learning is very powerful\"\n",
    "\"AI\"\n",
    "After tokenization, they become numbers\n",
    "[4, 7, 2]                 # \"I love AI\"\n",
    "[10, 6, 3, 8, 9]          # \"Deep learning is very powerful\"\n",
    "[2]                       # \"AI\"\n",
    "Lengths are 3,5,1\n",
    "Neural networks require fixed-size inputs\n",
    "[\n",
    "  [4, 7, 2],\n",
    "  [10, 6, 3, 8, 9],\n",
    "  [2]\n",
    "]\n",
    "Because:\n",
    "\n",
    "Arrays must be rectangular\n",
    "\n",
    "GPU computation needs same shape\n",
    "What does it do?\n",
    "\n",
    "It adds zeros to short sequences so all sequences have the same length.\n",
    "[\n",
    " [0, 0, 4, 7, 2],\n",
    " [10, 6, 3, 8, 9],\n",
    " [0, 0, 0, 0, 2]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b48c3-ba7a-42ea-9028-792dd21f7335",
   "metadata": {},
   "source": [
    "Sequential is a model container in Keras that lets you build a neural network layer by layer in order\n",
    "think of it as a straight pipeline\n",
    "it is called sequential because .layers are added one after another\n",
    ".output of one layer --> input of the next\n",
    "Input â†’ Layer1 â†’ Layer2 â†’ Layer3 â†’ Output\n",
    "ðŸ”· Why Do We Use Sequential?\n",
    "âœ… 1. Simplicity (Very Important for Learning)\n",
    "\n",
    "For most beginner and intermediate models:\n",
    "\n",
    "Text classification\n",
    "\n",
    "Image classification\n",
    "\n",
    "Regression\n",
    "\n",
    "RNN / LSTM models\n",
    "\n",
    "Sequential is:\n",
    "\n",
    "Easy to read\n",
    "\n",
    "Easy to debug\n",
    "\n",
    "Easy to train\n",
    "âœ… 2. Perfect for Linear Models\n",
    "\n",
    "If your architecture looks like this:\n",
    "\n",
    "Embedding â†’ RNN â†’ Dense\n",
    "\n",
    "\n",
    "Then Sequential is the best choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de67dcd6-5d08-4308-a717-3041a972ff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colums in the dataset:\n",
      "['ID', 'Area', 'City', 'Restaurant Price', 'Avg Rating', 'Total Rating', 'Food Item', 'Food Type', 'Delivery Time', 'Review']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('swiggy.csv')\n",
    "print(\"Colums in the dataset:\")\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bed3fca-4968-4f3d-be0f-9cbc949fc484",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Review\"] = data[\"Review\"].str.lower()\n",
    "data[\"Review\"] = data[\"Review\"].replace(r'[^a-z0-9\\s]','',regex=True)\n",
    "\n",
    "data['sentiment'] = data['Avg Rating'].apply(lambda x: 1 if x > 3.5 else 0)\n",
    "data = data.dropna() #Removes all rows in the DataFrame that have missing values (NaN).\n",
    "#mean rating greater than 3.5 become 1 and other 0 \n",
    "#lambda x: x + 1\n",
    "#mean def func(x):\n",
    "#return x + 1\n",
    "#What is lambda?A small anonymous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb87bf4-5778-4449-97b3-5cab71b146fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "max_length = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(data[\"Review\"])#fit_on_texts reads all text in the column.Builds internal mapping:Each unique word â†’ integer.More frequent words get smaller indices\n",
    "#tokenizer.word_index\n",
    "# Example output:\n",
    "#{'the': 1, 'and': 2, 'good': 3, 'product': 4, ...}\n",
    "#Only the most frequent 5000 words are kept (because of num_words=5000)\n",
    "X = pad_sequences(tokenizer.texts_to_sequences(data[\"Review\"]), maxlen=max_length)\n",
    "y = data['sentiment'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c44ce-f495-476d-99cf-fc1776a70d71",
   "metadata": {},
   "source": [
    "We will split the data into training, validation and test sets while maintaining the class distribution.\n",
    "\n",
    "train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) : Splits data into 80% training and 20% test sets, preserving sentiment class balance\n",
    "train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train) : Further splits training data into 90% training and 10% validation sets, keeping class distribution consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30212fb1-ad5d-4823-b00a-9e773ea457b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04378cd1-db60-456f-88c6-b4c39ded64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=max_features, output_dim=16,\n",
    "              input_length=max_length),\n",
    "    SimpleRNN(64, activation='tanh', return_sequences=False),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#Sequential = Keras model where layers are stacked one after another.Simple and easy to use for most feedforward and RNN/LSTM models.\n",
    "#Turns integers (word indices) into vectors (embeddings)\n",
    "\n",
    "#input_dim=max_features â†’ size of vocabulary (top 5000 words)\n",
    "\n",
    "#output_dim=16 â†’ each word becomes a 16-dimensional vector\n",
    "\n",
    "#input_length=max_length â†’ input sequences are of length 200\n",
    "#activation='tanh'\n",
    "\n",
    "#Activation function for the hidden state\n",
    "\n",
    "#tanh outputs values in [-1, 1]\n",
    "\n",
    "#It allows the network to represent positive and negative signals\n",
    "\n",
    "#Very common in RNNs\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e8dfe-0fdc-40da-aa79-a2f8be11bd0a",
   "metadata": {},
   "source": [
    "return_sequences\tOutput shape\tUse case\n",
    "False (default)\t(batch_size, units)\tOnly last hidden state â†’ good for classification\n",
    "True\t(batch_size, sequence_length, units)\tReturn hidden state at each time step â†’ useful for sequence-to-sequence tasks like translation or text generation\n",
    "Dense layer = fully connected layer\n",
    "a) 1 â†’ number of neurons\n",
    "\n",
    "Output layer á€™á€¾á€¬ neuron á€á€…á€ºá€á€¯ á€›á€¾á€­á€á€šá€º\n",
    "\n",
    "Binary classification (positive/negative sentiment) á€™á€¾á€¬ 1 neuron á€œá€¯á€¶á€œá€±á€¬á€€á€ºá€á€šá€º\n",
    "\n",
    "Output = probability of positive class\n",
    "\n",
    "b) activation='sigmoid'\n",
    "\n",
    "Sigmoid function = \n",
    "ðœŽ\n",
    "(\n",
    "ð‘¥\n",
    ")\n",
    "=\n",
    "1\n",
    "1\n",
    "+\n",
    "ð‘’\n",
    "âˆ’\n",
    "ð‘¥\n",
    "Ïƒ(x)=\n",
    "1+e\n",
    "âˆ’x\n",
    "1\n",
    "\tâ€‹\n",
    "\n",
    "\n",
    "Input value (from RNN) â†’ converts to range [0, 1]\n",
    "\n",
    "Meaning: probability of positive sentiment\n",
    "1ï¸âƒ£ loss='binary_crossentropy'\n",
    "\n",
    "Loss function = model error á€€á€­á€¯ measure á€œá€¯á€•á€ºá€á€¬\n",
    "\n",
    "Binary classification (positive/negative sentiment) á€¡á€á€½á€€á€º á€¡á€žá€¯á€¶á€¸á€•á€¼á€¯á€á€šá€º\n",
    "\n",
    "Formula:\n",
    "\n",
    "loss\n",
    "=\n",
    "âˆ’\n",
    "1\n",
    "ð‘\n",
    "âˆ‘\n",
    "ð‘–\n",
    "=\n",
    "1\n",
    "ð‘\n",
    "[\n",
    "ð‘¦\n",
    "ð‘–\n",
    "log\n",
    "â¡\n",
    "(\n",
    "ð‘\n",
    "ð‘–\n",
    ")\n",
    "+\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "ð‘¦\n",
    "ð‘–\n",
    ")\n",
    "log\n",
    "â¡\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "ð‘\n",
    "ð‘–\n",
    ")\n",
    "]\n",
    "loss=âˆ’\n",
    "N\n",
    "1\n",
    "\tâ€‹\n",
    "\n",
    "i=1\n",
    "âˆ‘\n",
    "N\n",
    "\tâ€‹\n",
    "\n",
    "[y\n",
    "i\n",
    "\tâ€‹\n",
    "\n",
    "log(p\n",
    "i\n",
    "\tâ€‹\n",
    "\n",
    ")+(1âˆ’y\n",
    "i\n",
    "\tâ€‹\n",
    "\n",
    ")log(1âˆ’p\n",
    "i\n",
    "\tâ€‹\n",
    "\n",
    ")]\n",
    "\n",
    "ð‘¦\n",
    "ð‘–\n",
    "y\n",
    "i\n",
    "\tâ€‹\n",
    "\n",
    " = true label (0 or 1)\n",
    "\n",
    "ð‘\n",
    "ð‘–\n",
    "p\n",
    "i\n",
    "\tâ€‹\n",
    "\n",
    " = predicted probability (output of sigmoid)\n",
    "\n",
    "Meaning:\n",
    "\n",
    "Model prediction á€”á€²á€· true label á€€á€½á€¬á€á€¼á€¬á€¸á€™á€¾á€¯á€€á€­á€¯ quantify á€œá€¯á€•á€ºá€á€šá€º\n",
    "\n",
    "Loss á€œá€»á€±á€¬á€·á€žá€½á€¬á€¸ â†’ Model á€œá€±á€·á€œá€¬á€™á€¾á€¯á€€á€±á€¬á€„á€ºá€¸á€œá€¬á€á€¬\n",
    "Metrics = training & validation performance á€€á€­á€¯ track\n",
    "\n",
    "accuracy â†’ percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ba69bb-1f54-4bfd-ac87-f5a1f78f9af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m180/180\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.7149 - loss: 0.6019 - val_accuracy: 0.7156 - val_loss: 0.5999\n",
      "Epoch 2/5\n",
      "\u001b[1m180/180\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.7160 - loss: 0.5981 - val_accuracy: 0.7156 - val_loss: 0.6026\n",
      "Epoch 3/5\n",
      "\u001b[1m180/180\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.7160 - loss: 0.5980 - val_accuracy: 0.7156 - val_loss: 0.5962\n",
      "Epoch 4/5\n",
      "\u001b[1m180/180\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.7160 - loss: 0.5971 - val_accuracy: 0.7156 - val_loss: 0.5958\n",
      "Epoch 5/5\n",
      "\u001b[1m180/180\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.7160 - loss: 0.5969 - val_accuracy: 0.7156 - val_loss: 0.5969\n",
      "Test accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {score[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3135ae-e663-4457-a5ce-b8f3eebeea6b",
   "metadata": {},
   "source": [
    "| Parameter                        | Explanation                                                        |\n",
    "| -------------------------------- | ------------------------------------------------------------------ |\n",
    "| `X_train, y_train`               | Training data (inputs and labels)                                  |\n",
    "| `epochs=5`                       | Dataset á€€á€­á€¯ **5 á€€á€¼á€­á€™á€º** iterate á€œá€¯á€•á€ºá€™á€šá€º (full pass)                |\n",
    "| `batch_size=32`                  | **32 sample** á€á€…á€ºá€á€¯á€á€»á€„á€ºá€¸ batch á€œá€¯á€•á€ºá€•á€¼á€®á€¸ weight update á€œá€¯á€•á€ºá€™á€šá€º      |\n",
    "| `validation_data=(X_val, y_val)` | Training á€¡á€á€½á€„á€ºá€¸ performance á€…á€…á€ºá€–á€­á€¯á€· **validation set** á€€á€­á€¯ á€žá€¯á€¶á€¸á€™á€šá€º |\n",
    "| `verbose=1`                      | Training progress á€€á€­á€¯ **output terminal** á€™á€¾á€¬ print                |\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "Purpose: Final test evaluation after training\n",
    "\n",
    "Test set = completely unseen data\n",
    "\n",
    "Returns a list: [loss, accuracy] (because metrics=['accuracy'] in compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea2e487a-22d9-41be-a07d-a77d2e133c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The food was great.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "Sentiment: Positive (Probability: 0.72)\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(review_text):\n",
    "    text = review_text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=max_length)\n",
    "\n",
    "    prediction = model.predict(padded)[0][0]\n",
    "    return f\"{'Positive' if prediction >= 0.5 else 'Negative'} (Probability: {prediction:.2f})\"\n",
    "\n",
    "\n",
    "sample_review = \"The food was great.\"\n",
    "print(f\"Review: {sample_review}\")\n",
    "print(f\"Sentiment: {predict_sentiment(sample_review)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b757e52-11cd-4038-9571-a02df080f2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
